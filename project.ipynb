{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution\n",
    "## Data Loading and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "PATH = \"Prakhar/er-assignment/fs/Instabase%20Drive/files/datasets/\"\n",
    "FILES = {\n",
    "    \"foursquare_test\": \"foursquare_test_hard.json\",\n",
    "    \"locu_test\": \"locu_test_hard.json\",\n",
    "    \"matches\": \"matches_train_hard.csv\",\n",
    "    \"foursquare_train\": \"foursquare_train_hard.json\",\n",
    "    \"locu_train\": \"locu_train_hard.json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs_train = pd.read_json(ib.open(PATH + FILES[\"foursquare_train\"]))\n",
    "fs_test = pd.read_json(ib.open(PATH + FILES[\"foursquare_test\"]))\n",
    "lc_train = pd.read_json(ib.open(PATH + FILES[\"locu_train\"]))\n",
    "lc_test = pd.read_json(ib.open(PATH + FILES[\"locu_test\"]))\n",
    "matches = pd.read_csv(ib.open(PATH + FILES[\"matches\"]))\n",
    "\n",
    "data_list = [fs_train, fs_test, lc_train, lc_test]\n",
    "\n",
    "for df in data_list:\n",
    "    df.drop(['country', 'region', 'locality'], inplace=True, axis=1)\n",
    "    \n",
    "    df.replace([''], [None], inplace=True)\n",
    "    \n",
    "    df['id'] = df['id'].astype('str')\n",
    "    df['latitude'] = pd.to_numeric(df['latitude'])\n",
    "    df['longitude'] = pd.to_numeric(df['longitude'])\n",
    "#     df['locality'] = df['locality'].astype('str')\n",
    "    \n",
    "    # Unicode chars to replace\n",
    "    df['name'].replace([u\"\\xe9\"], ['e'], regex=True, inplace=True)\n",
    "    df['name'].replace([u\"\\xed\"], ['i'], regex=True, inplace=True)\n",
    "    df['name'].replace([u'\\u2019'], [''], regex=True, inplace=True)\n",
    "    df['name'].replace([u'\\xc7'], ['c'], regex=True, inplace=True)\n",
    "    df['name'].replace([u'\\u2013'], ['-'], regex=True, inplace=True)\n",
    "    \n",
    "    df['name'].replace([r':|\\'|,|\\.|-'], [''], regex=True, inplace=True)\n",
    "    df['name'].replace(['&'], ['and'], regex=True, inplace=True)\n",
    "    df['name'].replace(['\\s+|\\/'], [' '], regex=True, inplace=True)\n",
    "\n",
    "    df['name'] = df['name'].astype(str).str.lower()\n",
    "    \n",
    "    df['phone'].replace([r'\\(|\\)|\\s|-'], [''], regex=True, inplace=True)\n",
    "    \n",
    "    df['street_address'].replace([r'<sup>|<\\/sup>'], [''], regex=True, inplace=True)\n",
    "    df['street_address'] = df['street_address'].astype(str)\n",
    "    \n",
    "    df['website'].replace([u\"\\u200e\"], [''], regex=True, inplace=True)\n",
    "    df['website'].replace([r'http(s)?://(www.)?|\\\\u200e'], [''], regex=True, inplace=True)\n",
    "    df['website'].replace([r'\\..*'], [''], regex=True, inplace=True)\n",
    "    df['website'] = df['website'].astype(str).str.lower()\n",
    "    df['website'].replace(['None'], [None], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append a prefix to identify the columns when concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for df in [fs_train, fs_test]:\n",
    "    df.columns = ['fs_' + str(i) for i in list(df.columns)]\n",
    "for df in [lc_train, lc_test]:\n",
    "    df.columns = ['lc_' + str(i) for i in list(df.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Row Combinations\n",
    "LC data is repeated row at a time, then FS data is repeated entirely at a time. The two are concatenated to create the combo data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_left =  lc_train.loc[np.repeat(lc_train.index.values, len(lc_train))].reset_index(drop=True)\n",
    "train_right =  pd.concat([fs_train]*len(fs_train), ignore_index=True)\n",
    "train = pd.concat([train_left, train_right], axis=1)\n",
    "\n",
    "test_left =  lc_test.loc[np.repeat(lc_test.index.values, len(lc_test))].reset_index(drop=True)\n",
    "test_right =  pd.concat([fs_test]*len(fs_test), ignore_index=True)\n",
    "test = pd.concat([test_left, test_right], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_distance(pt1, pt2):\n",
    "    return math.sqrt( (pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2 )\n",
    "    \n",
    "def string_similarity(str1, str2):\n",
    "  return SequenceMatcher(None, str1, str2).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary testing only using distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs_train_dict, lc_train_dict, fs_test_dict, lc_test_dict = {}, {}, {}, {}\n",
    "for i, row in fs_train.iterrows():\n",
    "    fs_train_dict[row['id']] = (row['latitude'], row['longitude'])\n",
    "for i, row in lc_train.iterrows():\n",
    "    lc_train_dict[row['id']] = (row['latitude'], row['longitude'])\n",
    "for i, row in fs_test.iterrows():\n",
    "    fs_test_dict[row['id']] = (row['latitude'], row['longitude'])\n",
    "for i, row in lc_test.iterrows():\n",
    "    lc_test_dict[row['id']] = (row['latitude'], row['longitude'])\n",
    "    \n",
    "matches_pred = {}\n",
    "for lc_key, lc_loc in lc_train_dict.iteritems():\n",
    "    min_dist = float(\"inf\")\n",
    "    min_loc = None\n",
    "    for fs_key, fs_loc in fs_train_dict.iteritems():\n",
    "        dist = find_distance(lc_loc, fs_loc)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_key = fs_key\n",
    "    matches_pred[lc_key] = min_key\n",
    "    \n",
    "count = 0\n",
    "for _, row in matches.iterrows():\n",
    "    lc_id = row['locu_id']\n",
    "    fs_id = row['foursquare_id']\n",
    "    if matches_pred[lc_id] == fs_id:\n",
    "        count += 1\n",
    "print(count / float(len(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches_pred_test = {}\n",
    "for lc_key, lc_loc in lc_test_dict.iteritems():\n",
    "    min_dist = float(\"inf\")\n",
    "    min_loc = None\n",
    "    for fs_key, fs_loc in fs_test_dict.iteritems():\n",
    "        dist = find_distance(lc_loc, fs_loc)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_key = fs_key\n",
    "    matches_pred_test[lc_key] = min_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "username = \"woojink\"\n",
    "repo = \"best-entity-resolvers\"\n",
    "f = ib.open('/{0}/{1}/fs/Instabase%20Drive/files/matches.csv'.format(username,repo))\n",
    "\n",
    "# with open('output.csv', 'w') as csvfile:\n",
    "writer = csv.writer(f)\n",
    "\n",
    "header = ['locu_id', 'foursquare_id']\n",
    "writer.writerow(header)\n",
    "for key, val in matches_pred_test.iteritems():\n",
    "    writer.writerow([key, val])\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
